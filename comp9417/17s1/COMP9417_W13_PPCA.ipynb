{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and PPCA\n",
    "## COMP9417-17s1, W13 Tutorial, Exercise 2\n",
    "### Instructor: Edwin V. Bonilla\n",
    "#### School of Computer Science and Engineering, UNSW Sydney "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will further explore the concepts in Principal Component Analysis (**PCA**) and Probabilistic Principal Component Analysis (**PPCA**). You are provided with the data file *usps\\_ppca.mat* which contains the variable _x2tr_,  _x3tr_ and   _xte_. The main goal of this exercise is to understand how to fit (estimate) a PPCA model for dimensionality reduction and how to use it for classification following a probabilistic class-conditional modelling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a few useful functions and imports that we will use later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "def plot_image(array, dim=16):\n",
    "    \"\"\"\n",
    "    Plot array as an image of dimensions dim * dim\n",
    "    \"\"\"\n",
    "    img = array.reshape(dim,dim, order = \"F\")\n",
    "    pl.imshow(img, cmap=pl.cm.gray)\n",
    "    ax = pl.gca();ax.set_yticks([]);ax.set_xticks([])\n",
    "    \n",
    "def get_eigenspectrum(x):\n",
    "    \"\"\"\n",
    "    Get the eigenspectrum of the covariance of x.\n",
    "    :param x: (N,D)-dimensional array \n",
    "    :return l: 1-dimensional array of ordered eigenvalues\n",
    "    :return E: (N,N)-dimensional array of corresponing eigenvectors, \n",
    "        where each column is an eigenvector\n",
    "    :return p: 1-dimensional array with cumulative variances \n",
    "    \"\"\"\n",
    "    S = np.cov(x, rowvar=False)\n",
    "    l, E = np.linalg.eig(S)\n",
    "    idx = np.argsort(l)[::-1]\n",
    "    l = l[idx]\n",
    "    E = E[:,idx]\n",
    "    p = l / np.sum(l)\n",
    "    p = np.cumsum(p)\n",
    "    return l, E, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For historical reasons these data are in matlab format, so we proceed to loading them using _loadmat_ from scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat('usps_ppca.mat')\n",
    "x2tr = data['x2tr']\n",
    "x3tr = data['x3tr']\n",
    "xte = data['xte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays above are $N \\times D$ matrices whose rows correspond to vectorial representations of the digits 2 and 3, where $N$ is the number of datapoints and  $D=256$ is the dimensionality of the vectors. We then check their dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points for class 2 = 500\n",
      "Number of training points for class 3 = 500\n",
      "Number of test points = 600\n",
      "Dimensionality of the inputs = 256\n"
     ]
    }
   ],
   "source": [
    "N2_tr, D2_tr = x2tr.shape\n",
    "N3_tr, D3_tr = x3tr.shape\n",
    "N_te, D_te = xte.shape\n",
    "print(\"Number of training points for class 2 = \" + repr(N2_tr) )\n",
    "print(\"Number of training points for class 3 = \" + repr(N3_tr) )\n",
    "print(\"Number of test points = \" + repr(N_te) )\n",
    "print(\"Dimensionality of the inputs = \" + repr(D2_tr) )  # This should be the same for all arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform one of these vectors, say the 5th row of _x2tr_ into a $16 \\times 16$ grayscale image using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069a55d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(x2tr[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean of the $2$s dataset (_x2tr_) and visualize its grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function `get_eigenspectrum(x)` defined above, Get the eigenspectrum _l2, E2, p2_ of _x2tr_ and plot the top 4 eigenvectors. What variability is explained by each of these egeinvectors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative variance _p2_. What do you think the intrinsic dimensionality of these data is? How many components are required to explain at least $95\\%$ of the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recall that the ML estimates of the PPCA parameters are: $\\boldsymbol{\\mu}_{\\text{ML}} = \\bar{\\mathbf{x}}; \\quad \\mathbf{W}_{\\text{ML}} = \\mathbf{E} (\\mathbf{\\Lambda} - \\sigma_{\\text{ML}}^2 \\mathbf{I})^{1/2} \\mathbf{R}; \\quad \\sigma_{\\text{ML}}^2 = \\frac{1}{D-K} \\sum_{i=K+1}^D \\lambda_i$; where $D$ is the original input dimensionality; $K$ is the reduced dimensionality; $\\bar{\\mathbf{x}}$ is the sample mean; $\\{ \\lambda_i \\}$ are the ordered eigenvalues of the data covariance; $\\mathbf{\\Lambda}$ is a diagonal matrix with $\\{\\lambda_i\\}$ on its diagonal; $\\mathbf{E}$ is the matrix with corresponding eigenvectors on the columns; and $\\mathbf{R}$ is an arbitrary rotation matrix.\n",
    "\n",
    "Using $K=3$ and $\\mathbf{R} = \\mathbf{I}$, fit a PPCA model to _x2tr_ and _x3tr_ using maximum likelihood. Note that for _x2tr_ you have already computed the eigenspectrum. Name the corresponding variables _mu2_, _W2_, _var2_ and _mu3_, _W3_,  _var3_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the marginal distribution $p(\\mathbf{x})$ of the PPCA model is given by: $p(\\mathbf{x}) = \\mathcal{N} (\\mathbf{x}; \\boldsymbol{\\mu}, \\mathbf{C})$, where $\\boldsymbol{\\mu}$ is the mean of the PPCA model and $\\mathbf{C} = \\mathbf{W} \\mathbf{W}^T + \\sigma^2 \\mathbf{I}$. In order to compute the log probability of a single datapoint $\\mathbf{x}$ we then need to evaluate the log probability of the Gaussian above, which is given by: $\\log p(\\mathbf{x}) = - \\frac{1}{2} \\left[ \\log | \\mathbf{C} | + D  \\log 2 \\pi + (\\mathbf{x} - \\boldsymbol{\\mu})^T \\mathbf{C}^{-1} (\\mathbf{x}-\\boldsymbol\\mu) \\right]$. This involves the computaion of the determinant and the inverse of the covariance matrix $\\mathbf{C}$, which can be computed using: $\\mathbf{C}^{-1} = \\sigma^{-1} \\mathbf{I} - \\sigma^{-2} \\mathbf{W} \\mathbf{M}^{-1} \\mathbf{W}^T$ with $\\mathbf{M} = \\mathbf{W}^T \\mathbf{W} + \\sigma^2 \\mathbf{I}$; and $\\log |\\mathbf{C}| = \\sum_{k=1}^{K} \\log \\lambda_k + (D-K) \\log \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(a)*** Why is computing the inverse above more efficient than computing to the inverse of $\\mathbf{C}$ directly according to its definition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(b)*** What is the intuition of the expression for  $\\log |\\mathbf{C}|$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below computes the log probability of a datapoint _x_ under a PPCA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logprob_PPCA(l, mu, W, var, x):\n",
    "    \"\"\"\n",
    "    Compute the log probability of a point x under a PPCA model.\n",
    "    @param l: Selected K eigenvalues of the PPCA model\n",
    "    @param mu: mean of the PPCA model\n",
    "    @param W: (D,K)-dimensional array of weights of PPCA model\n",
    "    @param var: Variance of the PPCA model\n",
    "    @param x: Test point to compute the log probability under the model\n",
    "    \"\"\"\n",
    "    xtilde = x - mu\n",
    "    D, K = W.shape\n",
    "    Ik = np.eye(K)\n",
    "    Id = np.eye(D)\n",
    "    Wt = np.transpose(W)\n",
    "    M = np.dot(Wt,W) + var * Ik\n",
    "    Minv = np.linalg.inv(M)\n",
    "    Cinv = (1.0/np.sqrt(var))*Id - (1.0/var)*np.dot(W, np.dot(Minv, Wt)) \n",
    "    quad_term = np.sum(xtilde * np.dot(Cinv, xtilde))\n",
    "    logdet = np.sum(np.log(l)) + (D-K) * np.log(var)\n",
    "    logprob = - 0.5 * (logdet + D * np.log(2*np.pi) + quad_term)\n",
    "    return logprob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(a)*** Compute the log probability of each test datapoint in _xte_ under each of the PPCA models for 2s and 3s. Use these log probabilities to classify the test datapoints as a '2' or a '3' and count the number of points classified on each class. Make a bar plot of the resulting counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(b)*** Make an image plot of the mean of _xte_ and compare this to the results obtained in the previous item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
